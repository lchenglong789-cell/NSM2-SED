data: # change with your paths if different.
  synth_folder: "YOUR_PATH/DESED2022/synth_train+val/SynthDataset/Train/soundscapes_16k/"
  synth_folder_44k: "YOUR_PATH/DESED2022/synth_train+val/SynthDataset/Train/soundscapes_16k/"
  synth_tsv: "YOUR_PATH/DESED2022/annotations/synth_train(10000).tsv"
  strong_folder: "YOUR_PATH/DESED2022/strong_label_real/strong_label_real/"
  strong_folder_44k: "YOUR_PATH/DESED2022/strong_label_real/strong_label_real/"
  strong_val_tsv: "./val_utils/audioset_strong_val.tsv"
  strong_val_dur: "./val_utils/audioset_strong_val_dur.tsv"
  strong_tsv: "YOUR_PATH/DESED2022/annotations/audioset_strong_train.tsv"
  weak_folder: "YOUR_PATH/DESED2022/weak_16k/weak_16k/"
  weak_folder_44k:  "YOUR_PATH/DESED2022/weak_16k/weak_16k/"
  weak_tsv: "YOUR_PATH/DESED2022/annotations/weak(1578).tsv"
  unlabeled_folder: "YOUR_PATH/DESED2022/unlabel_in_domain/unlabel_in_domain_16k/"
  unlabeled_folder_44k: "YOUR_PATH/DESED2022/unlabel_in_domain/unlabel_in_domain_16k/"
  synth_val_folder: "YOUR_PATH/DESED2022/synth_train+val/SynthDataset/Val/soundscapes_16k/"
  synth_val_folder_44k: "YOUR_PATH/DESED2022/synth_train+val/SynthDataset/Val/soundscapes_16k/"
  synth_val_tsv: "YOUR_PATH/DESED2022/annotations/synth_val(2500).tsv"
  synth_val_dur: "YOUR_PATH/DESED2022/annotations/synth_val_duration.tsv"
  # If you want to check performance on public eval set, uncomment the following lines (make sure you have the data)
  # test_tsv: YOUR_PATH/public_eval/dataset/metadata/eval/public.tsv
  # test_folder_44k: YOUR_PATH/public_eval/dataset/audio/eval/public/
  # test_folder: YOUR_PATH/public_eval/dataset/audio/eval/public_16k/
  # test_dur: YOUR_PATH/public_eval/dataset/metadata/eval/public_dur.tsv
  test_folder: "YOUR_PATH/DESED2022/validation_16k/validation_16k/"
  test_folder_44k: "YOUR_PATH/DESED2022/validation_16k/validation_16k/"
  test_tsv: "YOUR_PATH/DESED2022/annotations/validation(1168).tsv"
  test_dur: "YOUR_PATH/DESED2022/annotations/validation_durations.tsv"
  eval_folder:  "YOUR_PATH/DESED2022/eval/eval23_16k/"
  eval_folder_44k:  "YOUR_PATH/DESED2022/eval/eval23_16k/"
  external_folder: # External data path extracted mannually
  external_tsv:
  external_weak_folder:
  external_weak_tsv:
  audio_max_len: 10
  fs: 16000
  net_subsample: 4

scaler:
  statistic: instance # instance or dataset-wide statistic
  normtype: minmax # minmax or standard or mean normalization
  dims: [1, 2] # dimensions over which normalization is applied
  savepath: ./scaler.ckpt # path to scaler checkpoint

feats:
  n_mels: 128
  n_filters: 2048
  hop_length: 256
  n_window: 2048
  sample_rate: 16000
  f_min: 0
  f_max: 8000

training:
  #batch size: [synth, weak, unlabel]
  batch_size: [8, 8, 16, 16]  # if you want to change the batch size, be careful of the total training steps.
  batch_size_val: 64  # 64
  const_max: 70 # max weight used for self supervised loss
  n_epochs_warmup: 150 # num epochs used for exponential warmup
  num_workers: 6 # change according to your cpu
  n_epochs: 1500 # max num epochs
  early_stop_patience: 200 # Same as number of epochs by default, so no early stopping used
  accumulate_batches: 1
  gradient_clip: 0. # 0 no gradient clipping
  median_window:  [6, 20, 7, 4, 7, 6, 6, 6, 6, 6] # default: [7, 7, 7, 7, 7, 7, 7, 7, 7, 7]
  val_thresholds: [0.5] # thresholds used to compute f1 intersection in validation.
  n_test_thresholds: 50 # number of thresholds used to compute psds in test
  ema_factor: 0.999 # ema factor for mean teacher
  self_sup_loss: mse # bce or mse for self supervised mean teacher loss
  backend: ddp # pytorch lightning backend, ddp, dp or None
  validation_interval: 10 # we use a large validation interval to save time
  weak_split: 0.9
  seed: 42
  deterministic: False  # deterministic must be false since we are using adaptive-pool
  precision: 32
  mixup: soft # Soft mixup gives the ratio of the mix to the labels, hard mixup gives a 1 to every label present.
  obj_metric_synth_type: intersection # intersection
  enable_progress_bar: True

opt:
  mode: adam # adam or sgd or both
  cnn_lr: 0.0002
  rnn_lr: 0.0002
  mamba_lr: 0.0002
  mamba_lr_scale: 0.5
  mamba_trainable_layers: 10 # max: 14; min: 0 for freezing

net:
  dropout: 0.5
  rnn_layers: 2
  n_in_channel: 1
  nclass: 10
  attention: True
  n_RNN_cell: 128
  activation: cg
  rnn_type: BGRU
  kernel_size: [3, 3, 3, 3, 3, 3, 3]
  padding: [1, 1, 1, 1, 1, 1, 1]
  stride: [1, 1, 1, 1, 1, 1, 1]
  nb_filters: [ 16, 32, 64, 128, 128, 128, 128 ]
  pooling: [ [ 2, 2 ], [ 2, 2 ], [ 1, 2 ], [ 1, 2 ], [ 1, 2 ], [ 1, 2 ], [ 1, 2 ] ]
  dropout_recurrent: 0
  use_embeddings: True
  embedding_size: 768
  embedding_type: frame
  aggregation_type: pool1d

ultra:
  amamba2_dropout: 0.0
  model_init:  "./stage1_train.ckpt" # path of model checkpoint from stage 1
  amamba2_init:  "./NCM2_AS2M.ckpt"  # absolute path to checkpoint
comments: